{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aqlm import QuantizedLinear\n",
    "from aqlm.utils import _dequantize_weight, unpack_int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2%] Built target pthreadpool\n",
      "[  8%] Built target cpuinfo_internals\n",
      "[  8%] Built target cpuinfo\n",
      "[  9%] Built target gflags_nothreads_static\n",
      "[ 17%] Built target eigen_blas\n",
      "[ 29%] Built target flatc\n",
      "[ 30%] \u001b[34m\u001b[1mGenerating common_schema headers\u001b[0m\n",
      "[ 30%] Built target common_schema\n",
      "[ 30%] \u001b[34m\u001b[1mGenerating program_schema headers\u001b[0m\n",
      "[ 30%] Built target program_schema\n",
      "[ 30%] \u001b[32mBuilding CXX object /Users/blacksamorez/reps/AQLM/inference_lib/src/aqlm/inference_kernels/executorch/CMakeFiles/executorch_no_prim_ops.dir/runtime/executor/method_meta.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object /Users/blacksamorez/reps/AQLM/inference_lib/src/aqlm/inference_kernels/executorch/CMakeFiles/executorch_no_prim_ops.dir/runtime/executor/method.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object /Users/blacksamorez/reps/AQLM/inference_lib/src/aqlm/inference_kernels/executorch/CMakeFiles/executorch_no_prim_ops.dir/runtime/executor/program.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object /Users/blacksamorez/reps/AQLM/inference_lib/src/aqlm/inference_kernels/executorch/CMakeFiles/executorch_no_prim_ops.dir/runtime/executor/tensor_parser_exec_aten.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object /Users/blacksamorez/reps/AQLM/inference_lib/src/aqlm/inference_kernels/executorch/CMakeFiles/executorch_no_prim_ops.dir/runtime/executor/tensor_parser_portable.cpp.o\u001b[0m\n",
      "[ 31%] \u001b[32m\u001b[1mLinking CXX static library libexecutorch_no_prim_ops.a\u001b[0m\n",
      "[ 36%] Built target executorch_no_prim_ops\n",
      "[ 36%] Built target cpublas\n",
      "[ 37%] Built target executorch\n",
      "[ 41%] Built target optimized_kernels\n",
      "[ 42%] Built target optimized_ops_lib\n",
      "[ 42%] \u001b[32m\u001b[1mLinking CXX shared library libaqlm.dylib\u001b[0m\n",
      "[ 42%] Built target aqlm\n",
      "[ 94%] Built target portable_kernels\n",
      "[ 98%] Built target optimized_native_cpu_ops_lib\n",
      "[ 98%] Built target portable_ops_lib\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable executor_runner\u001b[0m\n",
      "ld: warning: ignoring duplicate libraries: 'libexecutorch.a'\n",
      "[100%] Built target executor_runner\n"
     ]
    }
   ],
   "source": [
    "!bash build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 1024\n",
    "\n",
    "layer = QuantizedLinear(\n",
    "    in_features=SIZE,\n",
    "    out_features=SIZE * 3,\n",
    "    in_group_size=8,\n",
    "    out_group_size=1,\n",
    "    num_codebooks=2,\n",
    "    nbits_per_codebook=8,\n",
    "    bias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_weight = _dequantize_weight(\n",
    "    unpack_int_data(layer.codes, 8),\n",
    "    layer.codebooks,\n",
    "    layer.scales,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.rand((1, 1, SIZE)) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.ops.load_library(\"./cmake-out/libaqlm.dylib\")\n",
    "\n",
    "reference = input @ reference_weight.T + layer.bias\n",
    "test = torch.ops.aqlm.code2x8_lut_matmat(\n",
    "    input,\n",
    "    torch.permute(layer.codes, (1, 0, 2)).contiguous(),\n",
    "    layer.codebooks,\n",
    "    layer.scales,\n",
    "    layer.bias,\n",
    ")\n",
    "\n",
    "torch.testing.assert_close(\n",
    "    test,\n",
    "    reference,\n",
    "    atol=0.01,\n",
    "    rtol=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 ms, sys: 3.22 ms, total: 6.08 ms\n",
      "Wall time: 1.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):\n",
    "    input @ reference_weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 171 ms, sys: 31.5 ms, total: 202 ms\n",
      "Wall time: 35.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(10):\n",
    "    torch.ops.aqlm.code2x8_lut_matmat(\n",
    "        input,\n",
    "        torch.permute(layer.codes, (1, 0, 2)).contiguous(),\n",
    "        layer.codebooks,\n",
    "        layer.scales,\n",
    "        layer.bias,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
